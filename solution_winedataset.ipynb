{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    " \n",
    "df = pd.read_csv(\"wine.csv\")\n",
    "print(len(df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[df.columns[1:13]].values\n",
    "y = df[\"Wine\"].values\n",
    "y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.23,  1.71,  2.43, ...,  5.64,  1.04,  3.92],\n",
       "       [13.2 ,  1.78,  2.14, ...,  4.38,  1.05,  3.4 ],\n",
       "       [13.16,  2.36,  2.67, ...,  5.68,  1.03,  3.17],\n",
       "       ...,\n",
       "       [13.27,  4.28,  2.26, ..., 10.2 ,  0.59,  1.56],\n",
       "       [13.17,  2.59,  2.37, ...,  9.3 ,  0.6 ,  1.62],\n",
       "       [14.13,  4.1 ,  2.74, ...,  9.2 ,  0.61,  1.6 ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    71\n",
       "1    59\n",
       "3    48\n",
       "Name: Wine, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy=df[\"Wine\"]\n",
    "yy.value_counts()   # 3 different classes are present in wine column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\aarohi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\users\\aarohi\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=y.reshape(-1,1)\n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features=[0])  #Converted  scalar output into vector output where the correct class will be 1 and other will be 0\n",
    "\n",
    "Y= onehotencoder.fit_transform(y).toarray()\n",
    "Y\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.51861254, -0.5622498 ,  0.23205254, ...,  0.25171685,\n",
       "         0.36217728,  1.84791957],\n",
       "       [ 0.24628963, -0.49941338, -0.82799632, ..., -0.29332133,\n",
       "         0.40605066,  1.1134493 ],\n",
       "       [ 0.19687903,  0.02123125,  1.10933436, ...,  0.26901965,\n",
       "         0.31830389,  0.78858745],\n",
       "       ...,\n",
       "       [ 0.33275817,  1.74474449, -0.38935541, ...,  2.22423597,\n",
       "        -1.61212515, -1.48544548],\n",
       "       [ 0.20923168,  0.22769377,  0.01273209, ...,  1.83492299,\n",
       "        -1.56825176, -1.40069891],\n",
       "       [ 1.39508604,  1.58316512,  1.36520822, ...,  1.79166599,\n",
       "        -1.52437837, -1.42894777]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 12)\n",
      "(142, 3)\n",
      "(36, 12)\n",
      "(36, 3)\n"
     ]
    }
   ],
   "source": [
    "#Transform the data in training and testing\n",
    "#X,Y = shuffle(X,Y,random_state=1)\n",
    "train_x,test_x,train_y,test_y = train_test_split(X,Y,test_size=0.20, random_state=42)\n",
    "\n",
    "#print the shape of the train and test data values\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "training_epochs = 100\n",
    "cost_history = np.empty(shape=[1],dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32,[None,12])    # none is for batchsize but we are not dividing the data in batches so that's why we have used none and 12 means number of 12 features are there in our x\n",
    " \n",
    "W = tf.Variable(tf.zeros([12,3]))  #we are giving 0 as the initial value of weight and 12 weights for 3 different classes present in y\n",
    "#tf.zeros([3, 4], tf.int32)  # [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]\n",
    "\n",
    " \n",
    "b = tf.Variable(tf.zeros([3]))  #Bias is also initialized as 0.3 different bias values for 3 different classes present in y. We have 3 classes so we will be having 3 different perceptrons. 1 perceptron for 1 output class\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "W= [59,2] 59 is associated with inputs and 2 is associated with outputs as we are having 2 outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#initialize all variables.\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the cost function\n",
    "y_ = tf.placeholder(tf.float32,[None,3])   # none is for batch size and 3 means we have performed one hot encoding so we have 3 different columns for 3 different classes\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(x, W)+ b)    #matmul is matrix multiplication function and performed it on x,w.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_212:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_function = tf.reduce_mean(-tf.reduce_sum((y_ * tf.log(y)),reduction_indices=[1]))  # we are calculating the loss or error with cross entropy\n",
    "cost_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "passing it to Gradient Descent Optiimizer to minimize the loss which we have just calculated in above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the session\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "mse_history = []  # this list is for storing the mean square error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0  -  cost:  0.94974774\n",
      "epoch :  1  -  cost:  0.83556\n",
      "epoch :  2  -  cost:  0.74713844\n",
      "epoch :  3  -  cost:  0.6774491\n",
      "epoch :  4  -  cost:  0.621396\n",
      "epoch :  5  -  cost:  0.5754111\n",
      "epoch :  6  -  cost:  0.53700536\n",
      "epoch :  7  -  cost:  0.5044238\n",
      "epoch :  8  -  cost:  0.47640625\n",
      "epoch :  9  -  cost:  0.45203018\n",
      "epoch :  10  -  cost:  0.43060657\n",
      "epoch :  11  -  cost:  0.4116114\n",
      "epoch :  12  -  cost:  0.39463887\n",
      "epoch :  13  -  cost:  0.37937027\n",
      "epoch :  14  -  cost:  0.3655515\n",
      "epoch :  15  -  cost:  0.35297737\n",
      "epoch :  16  -  cost:  0.34148034\n",
      "epoch :  17  -  cost:  0.3309222\n",
      "epoch :  18  -  cost:  0.32118788\n",
      "epoch :  19  -  cost:  0.31218064\n",
      "epoch :  20  -  cost:  0.3038187\n",
      "epoch :  21  -  cost:  0.2960321\n",
      "epoch :  22  -  cost:  0.2887611\n",
      "epoch :  23  -  cost:  0.2819539\n",
      "epoch :  24  -  cost:  0.27556565\n",
      "epoch :  25  -  cost:  0.26955703\n",
      "epoch :  26  -  cost:  0.2638939\n",
      "epoch :  27  -  cost:  0.25854582\n",
      "epoch :  28  -  cost:  0.25348604\n",
      "epoch :  29  -  cost:  0.24869083\n",
      "epoch :  30  -  cost:  0.24413902\n",
      "epoch :  31  -  cost:  0.23981154\n",
      "epoch :  32  -  cost:  0.23569153\n",
      "epoch :  33  -  cost:  0.23176365\n",
      "epoch :  34  -  cost:  0.2280141\n",
      "epoch :  35  -  cost:  0.22443037\n",
      "epoch :  36  -  cost:  0.22100115\n",
      "epoch :  37  -  cost:  0.21771611\n",
      "epoch :  38  -  cost:  0.21456586\n",
      "epoch :  39  -  cost:  0.21154183\n",
      "epoch :  40  -  cost:  0.20863618\n",
      "epoch :  41  -  cost:  0.20584168\n",
      "epoch :  42  -  cost:  0.20315167\n",
      "epoch :  43  -  cost:  0.2005601\n",
      "epoch :  44  -  cost:  0.19806133\n",
      "epoch :  45  -  cost:  0.19565018\n",
      "epoch :  46  -  cost:  0.19332182\n",
      "epoch :  47  -  cost:  0.19107178\n",
      "epoch :  48  -  cost:  0.18889594\n",
      "epoch :  49  -  cost:  0.18679044\n",
      "epoch :  50  -  cost:  0.18475172\n",
      "epoch :  51  -  cost:  0.18277642\n",
      "epoch :  52  -  cost:  0.18086143\n",
      "epoch :  53  -  cost:  0.17900386\n",
      "epoch :  54  -  cost:  0.17720096\n",
      "epoch :  55  -  cost:  0.1754502\n",
      "epoch :  56  -  cost:  0.17374918\n",
      "epoch :  57  -  cost:  0.17209567\n",
      "epoch :  58  -  cost:  0.17048754\n",
      "epoch :  59  -  cost:  0.16892283\n",
      "epoch :  60  -  cost:  0.16739963\n",
      "epoch :  61  -  cost:  0.16591626\n",
      "epoch :  62  -  cost:  0.16447102\n",
      "epoch :  63  -  cost:  0.1630623\n",
      "epoch :  64  -  cost:  0.1616887\n",
      "epoch :  65  -  cost:  0.16034877\n",
      "epoch :  66  -  cost:  0.1590412\n",
      "epoch :  67  -  cost:  0.15776473\n",
      "epoch :  68  -  cost:  0.15651818\n",
      "epoch :  69  -  cost:  0.15530041\n",
      "epoch :  70  -  cost:  0.1541104\n",
      "epoch :  71  -  cost:  0.15294707\n",
      "epoch :  72  -  cost:  0.15180948\n",
      "epoch :  73  -  cost:  0.15069672\n",
      "epoch :  74  -  cost:  0.14960791\n",
      "epoch :  75  -  cost:  0.14854223\n",
      "epoch :  76  -  cost:  0.14749886\n",
      "epoch :  77  -  cost:  0.14647706\n",
      "epoch :  78  -  cost:  0.1454761\n",
      "epoch :  79  -  cost:  0.14449531\n",
      "epoch :  80  -  cost:  0.143534\n",
      "epoch :  81  -  cost:  0.14259155\n",
      "epoch :  82  -  cost:  0.1416674\n",
      "epoch :  83  -  cost:  0.14076093\n",
      "epoch :  84  -  cost:  0.13987161\n",
      "epoch :  85  -  cost:  0.13899891\n",
      "epoch :  86  -  cost:  0.13814229\n",
      "epoch :  87  -  cost:  0.1373013\n",
      "epoch :  88  -  cost:  0.13647549\n",
      "epoch :  89  -  cost:  0.13566439\n",
      "epoch :  90  -  cost:  0.13486756\n",
      "epoch :  91  -  cost:  0.13408463\n",
      "epoch :  92  -  cost:  0.13331518\n",
      "epoch :  93  -  cost:  0.13255882\n",
      "epoch :  94  -  cost:  0.13181518\n",
      "epoch :  95  -  cost:  0.13108397\n",
      "epoch :  96  -  cost:  0.13036476\n",
      "epoch :  97  -  cost:  0.1296573\n",
      "epoch :  98  -  cost:  0.12896127\n",
      "epoch :  99  -  cost:  0.1282763\n"
     ]
    }
   ],
   "source": [
    "#calculate the cost for each epoch\n",
    "for i in range(100):\n",
    "    sess.run(training_step,feed_dict=({x: train_x, y_: train_y}))\n",
    "    cost = sess.run(cost_function,feed_dict={x: train_x,y_:train_y})\n",
    "    cost_history = np.append(cost_history,cost) #cost history we have created previously and using it here just to store the cost of each epoch\n",
    "\n",
    "    #after above 3 lines weights get updated and once we have updated weights we will evaluate the test data set. \n",
    "\n",
    "    pred_y = sess.run(y, feed_dict={x: test_x})  # y is a linear model which is using softmax function. Once we update the weights we will evaluate it on the test_x\n",
    "    print('epoch : ', i,  ' - ', 'cost: ', cost)  # printing cost or error associated with each epoch\n",
    "    \n",
    "    # we want to calculate the mean square error now\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - test_y))  # test_y is the target output and pred_y is the predicted output\n",
    "    mse_history.append(sess.run(mse))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "error reduced from 50 to 46 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: [0.18894439940450042, 0.16193733206552777, 0.14045502232825477, 0.12339374088655729, 0.10972975877916465, 0.09865183157047165, 0.0895534762934186, 0.08198837727779074, 0.07562704317017602, 0.0702235307035118, 0.06559168336829736, 0.061588599813637214, 0.05810308534093083, 0.0550475428811419, 0.05235218587799766, 0.049960840732355724, 0.04782788157195735, 0.04591593530783374, 0.044194162870550564, 0.04263691407752348, 0.04122274449047803, 0.03993360033945342, 0.038754199720894444, 0.03767154580963875, 0.036674515827462305, 0.03575356944293411, 0.03490046200815408, 0.0341080588264172, 0.03337014913157798, 0.032681312443393055, 0.03203679795521287, 0.03143242662440209, 0.0308645211145804, 0.03032981793315343, 0.029825422661081583, 0.029348758698862266, 0.0288975325225267, 0.0284696864239212, 0.028063370239097114, 0.02767693069915417, 0.0273088687465707, 0.026957830904314067, 0.026622599230278515, 0.02630205814328606, 0.025995201222089755, 0.025701106188765706, 0.025418936302253472, 0.025147919110491294, 0.02488735866192396, 0.024636603368220607, 0.024395065473415745, 0.024162191630766095, 0.023937490181869574, 0.023720483119121387, 0.02351075118122867, 0.02330789346040038, 0.023111540645450086, 0.022921348053561993, 0.022737000854769488, 0.02255819950603702, 0.022384667740644768, 0.022216151537750237, 0.022052406975362194, 0.02189320962335162, 0.021738348500777677, 0.021587624241321685, 0.02144085455850778, 0.021297862532056212, 0.021158486555867575, 0.021022570120852384, 0.020889971752994577, 0.020760551575670094, 0.020634181803068332, 0.020510742687808038, 0.020390116302527253, 0.02027219180471073, 0.02015687117842868, 0.02004405225043531, 0.019933646250317977, 0.019825563492968837, 0.019719719441166572, 0.019616035154338983, 0.019514439085320873, 0.01941485397251656, 0.019317217240538483, 0.019221459694199878, 0.019127520637461152, 0.019035341856752073, 0.018944866565472205, 0.018856037461860445, 0.01876880654081909, 0.018683127507264526, 0.0185989487932054, 0.01851622677459967, 0.018434915874642122, 0.018354978342421897, 0.018276371463867097, 0.01819906080352138, 0.01812300969697606, 0.01804818128412346]\n"
     ]
    }
   ],
   "source": [
    "#print the final mean square error\n",
    "\n",
    "print(\"MSE:\",mse_history)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mse_history, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
